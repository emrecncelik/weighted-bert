{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from weighted_bert.models import WeightedAverage, WeightedRemoval\n",
    "\n",
    "logging.basicConfig(level=\"DEBUG\")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using a HuggingFace model for NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighting_checkpoint = \"savasy/bert-base-turkish-ner-cased\"\n",
    "embedding_checkpoint = \"emrecan/bert-base-turkish-cased-mean-nli-stsb-tr\"\n",
    "\n",
    "documents = [\n",
    "[\n",
    "    \"Tesla'nın otomobilleri insan hayatlarını riske atıyor olabilir.\",\n",
    "    \"Türkiye ve Kore arasında gerçekleşen voleybol müsabakasını Türkiye Milli Takımı kazandı.\",\n",
    "    \"Bu bir metin.\",\n",
    "],\n",
    "[\n",
    "    \"Mustafa Kemal Atatürk 19 Mayıs 1919'da Samsun'a ayak bastı.\",\n",
    "    \"Bu bir metin.\",\n",
    "],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: emrecan/bert-base-turkish-cased-mean-nli-stsb-tr\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"GET /api/models/emrecan/bert-base-turkish-cased-mean-nli-stsb-tr HTTP/1.1\" 200 1605\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /emrecan/bert-base-turkish-cased-mean-nli-stsb-tr/resolve/c4d66371214a20c0c91a39c83351ddc24f398800/.gitattributes HTTP/1.1\" 200 0\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /emrecan/bert-base-turkish-cased-mean-nli-stsb-tr/resolve/c4d66371214a20c0c91a39c83351ddc24f398800/README.md HTTP/1.1\" 200 0\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /emrecan/bert-base-turkish-cased-mean-nli-stsb-tr/resolve/c4d66371214a20c0c91a39c83351ddc24f398800/config.json HTTP/1.1\" 200 0\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /emrecan/bert-base-turkish-cased-mean-nli-stsb-tr/resolve/c4d66371214a20c0c91a39c83351ddc24f398800/config_sentence_transformers.json HTTP/1.1\" 200 0\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /emrecan/bert-base-turkish-cased-mean-nli-stsb-tr/resolve/c4d66371214a20c0c91a39c83351ddc24f398800/modules.json HTTP/1.1\" 200 0\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /emrecan/bert-base-turkish-cased-mean-nli-stsb-tr/resolve/c4d66371214a20c0c91a39c83351ddc24f398800/pytorch_model.bin HTTP/1.1\" 302 0\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /emrecan/bert-base-turkish-cased-mean-nli-stsb-tr/resolve/c4d66371214a20c0c91a39c83351ddc24f398800/sentence_bert_config.json HTTP/1.1\" 200 0\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /emrecan/bert-base-turkish-cased-mean-nli-stsb-tr/resolve/c4d66371214a20c0c91a39c83351ddc24f398800/special_tokens_map.json HTTP/1.1\" 200 0\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /emrecan/bert-base-turkish-cased-mean-nli-stsb-tr/resolve/c4d66371214a20c0c91a39c83351ddc24f398800/tokenizer.json HTTP/1.1\" 200 0\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /emrecan/bert-base-turkish-cased-mean-nli-stsb-tr/resolve/c4d66371214a20c0c91a39c83351ddc24f398800/tokenizer_config.json HTTP/1.1\" 200 0\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /emrecan/bert-base-turkish-cased-mean-nli-stsb-tr/resolve/c4d66371214a20c0c91a39c83351ddc24f398800/vocab.txt HTTP/1.1\" 200 0\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /emrecan/bert-base-turkish-cased-mean-nli-stsb-tr/resolve/c4d66371214a20c0c91a39c83351ddc24f398800/1_Pooling/config.json HTTP/1.1\" 200 0\n",
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device: cuda\n",
      "INFO:weighted_bert.models:================ Loading weighting model ================\n",
      "INFO:weighted_bert.models:\tsavasy/bert-base-turkish-ner-cased\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /savasy/bert-base-turkish-ner-cased/resolve/main/config.json HTTP/1.1\" 200 0\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /savasy/bert-base-turkish-ner-cased/resolve/main/pytorch_model.bin HTTP/1.1\" 302 0\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /savasy/bert-base-turkish-ner-cased/resolve/main/tokenizer_config.json HTTP/1.1\" 200 0\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /savasy/bert-base-turkish-ner-cased/resolve/main/config.json HTTP/1.1\" 200 0\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"GET /api/models/savasy/bert-base-turkish-ner-cased HTTP/1.1\" 200 966\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /savasy/bert-base-turkish-ner-cased/resolve/main/vocab.txt HTTP/1.1\" 200 0\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /savasy/bert-base-turkish-ner-cased/resolve/main/tokenizer.json HTTP/1.1\" 404 0\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /savasy/bert-base-turkish-ner-cased/resolve/main/added_tokens.json HTTP/1.1\" 404 0\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /savasy/bert-base-turkish-ner-cased/resolve/main/special_tokens_map.json HTTP/1.1\" 200 0\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /savasy/bert-base-turkish-ner-cased/resolve/main/tokenizer_config.json HTTP/1.1\" 200 0\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /savasy/bert-base-turkish-ner-cased/resolve/main/config.json HTTP/1.1\" 200 0\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /savasy/bert-base-turkish-ner-cased/resolve/main/config.json HTTP/1.1\" 200 0\n",
      "/home/emrecan/workspace/psychology-project/weighted-bert/venv/lib/python3.8/site-packages/transformers/pipelines/token_classification.py:128: UserWarning: `grouped_entities` is deprecated and will be removed in version v5.0.0, defaulted to `aggregation_strategy=\"AggregationStrategy.SIMPLE\"` instead.\n",
      "  warnings.warn(\n",
      "INFO:weighted_bert.models:================ Loading weighting model ================\n",
      "INFO:weighted_bert.models:\tsavasy/bert-base-turkish-ner-cased\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /savasy/bert-base-turkish-ner-cased/resolve/main/config.json HTTP/1.1\" 200 0\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /savasy/bert-base-turkish-ner-cased/resolve/main/pytorch_model.bin HTTP/1.1\" 302 0\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /savasy/bert-base-turkish-ner-cased/resolve/main/tokenizer_config.json HTTP/1.1\" 200 0\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /savasy/bert-base-turkish-ner-cased/resolve/main/config.json HTTP/1.1\" 200 0\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"GET /api/models/savasy/bert-base-turkish-ner-cased HTTP/1.1\" 200 966\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /savasy/bert-base-turkish-ner-cased/resolve/main/vocab.txt HTTP/1.1\" 200 0\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /savasy/bert-base-turkish-ner-cased/resolve/main/tokenizer.json HTTP/1.1\" 404 0\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /savasy/bert-base-turkish-ner-cased/resolve/main/added_tokens.json HTTP/1.1\" 404 0\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /savasy/bert-base-turkish-ner-cased/resolve/main/special_tokens_map.json HTTP/1.1\" 200 0\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /savasy/bert-base-turkish-ner-cased/resolve/main/tokenizer_config.json HTTP/1.1\" 200 0\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /savasy/bert-base-turkish-ner-cased/resolve/main/config.json HTTP/1.1\" 200 0\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /savasy/bert-base-turkish-ner-cased/resolve/main/config.json HTTP/1.1\" 200 0\n"
     ]
    }
   ],
   "source": [
    "# Initialize models\n",
    "embedding_model = SentenceTransformer(embedding_checkpoint)\n",
    "weighter_a = WeightedAverage(weighting_checkpoint)\n",
    "weighter_r = WeightedRemoval(weighting_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 35.16it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 52.27it/s]\n",
      "/home/emrecan/workspace/psychology-project/weighted-bert/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "DEBUG:weighted_bert.models:Entity count list for doc: [1, 3, 0]\n",
      "DEBUG:weighted_bert.models:Entity count list for doc: [2, 0]\n",
      "INFO:weighted_bert.models:================ Detecting entities ================\n",
      "DEBUG:weighted_bert.models:Entity count list for doc: [1, 3, 0]\n",
      "DEBUG:weighted_bert.models:Entity count list for doc: [2, 0]\n",
      "INFO:weighted_bert.models:================ Calculating initial document embeddings ================\n",
      "INFO:weighted_bert.models:================ Correcting document embeddings ================\n",
      "INFO:weighted_bert.models:\tCalculating first singular vector...\n",
      "INFO:weighted_bert.models:\tCalculating corrected embeddings...\n"
     ]
    }
   ],
   "source": [
    "# Calculate embeddings\n",
    "collection_sentence_embeddings = [embedding_model.encode(doc) for doc in documents]\n",
    "embeddings_a = np.array([weighter_a.get_document_embedding(doc, sentence_emb)\n",
    "                for doc, sentence_emb in zip(documents, collection_sentence_embeddings)])\n",
    "embeddings_r = weighter_r.get_document_embeddings(documents, collection_sentence_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2, 768), (2, 768))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_a.shape, embeddings_r.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using a rule based entity detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "from typing import List, Any\n",
    "\n",
    "def detect(sentence: str):\n",
    "    sentence_entites = [] \n",
    "    entity_list = ['tesla', \"atatürk\", \"türkiye\"]\n",
    "\n",
    "    for ent in entity_list:\n",
    "        matches = re.finditer(ent, sentence.lower())\n",
    "        indexes = [(match.start(), match.end()) for match in matches]\n",
    "        if indexes:\n",
    "            for start, end in indexes:\n",
    "                sentence_entites.append({\"text\": ent, \"start\": start, \"end\": end})\n",
    "    \n",
    "    return sentence_entites\n",
    "\n",
    "def entity_detector(document: List[str]) -> List[List[Any]]:\n",
    "    return [detect(sentence) for sentence in document]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:weighted_bert.models:Entity detector function you have provided is being used, not initializing HuggingFace model.\n",
      "INFO:weighted_bert.models:Entity detector function you have provided is being used, not initializing HuggingFace model.\n"
     ]
    }
   ],
   "source": [
    "# Initialize models\n",
    "weighter_a = WeightedAverage(entity_detector=entity_detector)\n",
    "weighter_r = WeightedRemoval(entity_detector=entity_detector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 50.35it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 76.67it/s]\n",
      "DEBUG:weighted_bert.models:Entity count list for doc: [1, 2, 0]\n",
      "DEBUG:weighted_bert.models:Entity count list for doc: [1, 0]\n",
      "INFO:weighted_bert.models:================ Detecting entities ================\n",
      "DEBUG:weighted_bert.models:Entity count list for doc: [1, 2, 0]\n",
      "DEBUG:weighted_bert.models:Entity count list for doc: [1, 0]\n",
      "INFO:weighted_bert.models:================ Calculating initial document embeddings ================\n",
      "INFO:weighted_bert.models:================ Correcting document embeddings ================\n",
      "INFO:weighted_bert.models:\tCalculating first singular vector...\n",
      "INFO:weighted_bert.models:\tCalculating corrected embeddings...\n"
     ]
    }
   ],
   "source": [
    "# Calculate embeddings\n",
    "collection_sentence_embeddings = [embedding_model.encode(doc) for doc in documents]\n",
    "embeddings_a = np.array([weighter_a.get_document_embedding(doc, sentence_emb)\n",
    "                for doc, sentence_emb in zip(documents, collection_sentence_embeddings)])\n",
    "embeddings_r = weighter_r.get_document_embeddings(documents, collection_sentence_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2, 768), (2, 768))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_a.shape, embeddings_r.shape"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "83bf2d3bd26546d38523b2bf511d3591181790cbdbf44d7b124f51cd603b50a8"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
